{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsy6I7ZGcqkc",
        "outputId": "2bd33395-c55e-41e7-d7d6-1f92a4bd50b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Where is the Eiffel Tower located?\n",
            "Answer: paris, france\n",
            "Cosine Similarity: 0.7997\n",
            "\n",
            "Question: How long is the Great Wall of China?\n",
            "Answer: 13, 000 miles\n",
            "Cosine Similarity: 0.7977\n",
            "\n",
            "Question: Who first climbed Mount Everest?\n",
            "Answer: sir edmund hillary and tenzing norgay\n",
            "Cosine Similarity: 0.6243\n",
            "\n",
            "Question: What are types of machine learning?\n",
            "Answer: supervised, unsupervised, and reinforcement learning\n",
            "Cosine Similarity: 0.6485\n",
            "\n",
            "Question: Name a framework used in deep learning.\n",
            "Answer: tensorflow and pytorch\n",
            "Cosine Similarity: 0.5892\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "qa_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
        "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "retrieval_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "def get_answer(question, context):\n",
        "    inputs = qa_tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    outputs = qa_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    start_idx = torch.argmax(start_scores)\n",
        "    end_idx = torch.argmax(end_scores) + 1\n",
        "\n",
        "    answer = qa_tokenizer.decode(input_ids[0][start_idx:end_idx], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "def retrieve_context(query, contexts):\n",
        "    query_embedding = retrieval_model.encode(query, convert_to_tensor=True)\n",
        "    context_embeddings = retrieval_model.encode(contexts, convert_to_tensor=True)\n",
        "\n",
        "    similarity_scores = util.pytorch_cos_sim(query_embedding, context_embeddings)\n",
        "    best_match_idx = torch.argmax(similarity_scores).item()\n",
        "    return contexts[best_match_idx], similarity_scores[0][best_match_idx].item()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sample_contexts = [\n",
        "        \"The Eiffel Tower, a wrought-iron lattice tower, is located in Paris, France. \"\n",
        "        \"It was named after the engineer Gustave Eiffel, whose company designed and built the tower. \"\n",
        "        \"The structure is 330 meters tall and is one of the most iconic landmarks in the world.\",\n",
        "\n",
        "        \"The Great Wall of China is a historic fortification that stretches across northern China. \"\n",
        "        \"Built to protect against invasions, the wall spans approximately 13,000 miles. \"\n",
        "        \"It is made of stone, brick, and other materials, and parts of it date back to the 7th century BC.\",\n",
        "\n",
        "        \"Mount Everest is the highest mountain in the world, with a peak reaching 8,848.86 meters above sea level. \"\n",
        "        \"Located in the Himalayas, it lies on the border between Nepal and the Tibet Autonomous Region of China. \"\n",
        "        \"The mountain was first successfully climbed by Sir Edmund Hillary and Tenzing Norgay in 1953.\",\n",
        "\n",
        "        \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on enabling machines to learn from data. \"\n",
        "        \"ML models can be classified into supervised, unsupervised, and reinforcement learning categories. \"\n",
        "        \"Popular algorithms include linear regression, decision trees, and neural networks.\",\n",
        "\n",
        "        \"Deep learning (DL) is a specialized branch of ML that uses neural networks with multiple layers, known as deep neural networks. \"\n",
        "        \"DL has driven advancements in fields such as computer vision, natural language processing, and speech recognition. \"\n",
        "        \"Key frameworks include TensorFlow and PyTorch.\"\n",
        "    ]\n",
        "\n",
        "    sample_questions = [\n",
        "        \"Where is the Eiffel Tower located?\",\n",
        "        \"How long is the Great Wall of China?\",\n",
        "        \"Who first climbed Mount Everest?\",\n",
        "        \"What are types of machine learning?\",\n",
        "        \"Name a framework used in deep learning.\"\n",
        "    ]\n",
        "\n",
        "    for question in sample_questions:\n",
        "        best_context, similarity = retrieve_context(question, sample_contexts)\n",
        "        answer = get_answer(question, best_context)\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {answer}\")\n",
        "        print(f\"Cosine Similarity: {similarity:.4f}\\n\")"
      ]
    }
  ]
}